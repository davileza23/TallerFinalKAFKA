ğŸ§ª Proyecto Final â€” Kafka + SQLite + Streamlit

Este proyecto demuestra una integraciÃ³n completa entre Kafka, SQLite y Streamlit para la publicaciÃ³n y consumo de datos en tiempo real.


ğŸ¯ Objetivo

Crear una base de datos local SQLite con datos de ejemplo (customers).

Publicar las filas como mensajes JSON en un tÃ³pico de Kafka.

Consumir y visualizar los mensajes desde una interfaz web hecha en Streamlit.

ğŸ—ï¸ Estructura del proyecto 
```
kafka_proy_final/
â”œâ”€â”€ docker-compose.yml           # (opcional, no usado en Podman)
â”œâ”€â”€ podman-compose.yml           # Servicios Kafka + Zookeeper + Kafdrop
â”œâ”€â”€ requirements.txt             # Dependencias de Python
â”œâ”€â”€ README.md                    # Instrucciones del proyecto
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app_streamlit.py         # Interfaz principal (DB â†’ Kafka â†’ Consumo)
â”‚   â”œâ”€â”€ create_db.py             # Script para crear sample.db con 3 filas
â”‚   â””â”€â”€ sample.db                # Base de datos SQLite generada
â””â”€â”€ capturas/                    # Evidencias del funcionamiento - archivo word

```


âš™ï¸ Requisitos previos

Python 3.9+ o superior WSL Ubuntu (o Linux nativo) Docker o Podman instalado y en ejecuciÃ³n


ğŸš€ Pasos de ejecuciÃ³n

Levantar Kafka
```
docker-compose up -d
##levantar kafka con podman-compose
podman-compose up -d
#listarlos
podman ps
```
Preparar entorno Python
```
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
##Comprobar entorno python
pip list
```
Abrir en el navegador: ğŸ‘‰ http://172.23.164.123:8501 En la pestaÃ±a DB â†’ Kafka: publica los datos. En Consumidor rÃ¡pido: verifica los mensajes desde el tÃ³pico customers_json.


ğŸ§© TecnologÃ­as usadas

Kafka / Zookeeper /kafdrop (Confluent 7.5.0) SQLite3 Streamlit 1.37+ Python 3.12 (WSL Ubuntu)


ğŸ“¸ Evidencias

Las capturas se encuentran dentro de la carpeta /capturas del proyecto (kafka_proy_final) esta alojado un documento de word que muestra el paso a paso de actividades realizadas, allÃ­ se evidencian la Interfaz Streamlit corriendo localmente. ConfirmaciÃ³n de Kafka activo en Podman. PublicaciÃ³n de datos hacia el tÃ³pico y Lectura de mensajes desde el consumidor.


ğŸ’¬ Responsable:
```
Diana Carolina Avilez Avilez
Taller Final de Kafka Universidad Santo TomÃ¡s/DIAN
GitHub: @davileza23
```
## Autor(a)

- [@davileza23](https://github.com/davileza23/TallerFinalKAFKA)


## DocumentaciÃ³n

[Evidencias ejecuciÃ³n proyecto final](https://github.com/davileza23/TallerFinalKAFKA/blob/main/kafka_proy_final/capturas/ProyectoFinalKafka.docx)

